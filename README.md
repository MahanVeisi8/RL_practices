# Reinforcement Learning Practices ðŸš€

![Python](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9-blue)
![Status](https://img.shields.io/badge/status-active-green)

Welcome to the Reinforcement Learning Practices repository! This repository hosts multiple projects, each dedicated to exploring different aspects and techniques of reinforcement learning across various problems and setups.

## Current Projects
- [CartPole RL Practices](Cartpole/): A collection of experiments and implementations focusing on the Cart Pole problem using various reinforcement learning algorithms.

<table>
  <tr>
    <td>Epoch 10<br><img src="assets/Cartpole/10epoch.gif" alt="Epoch 10 Performance" width="240px"></td>
    <td>Epoch 500<br><img src="assets/Cartpole/500epoch.gif" alt="Epoch 500 Performance" width="240px"></td>
    <td>Epoch 1000<br><img src="assets/Cartpole/1000epoch.gif" alt="Epoch 1000 Performance" width="240px"></td>
  </tr>
</table>

## Overview

### CartPole RL Practices
This project is an extensive exploration of different reinforcement learning strategies applied to the classic Cart Pole problem. Each subdirectory focuses on a unique RL algorithm or aspect, providing deep dives into their setup, implementation, and performance analysis.

#### Highlights:
- **Deep Q-Networks (DQN)**
- **Hyperparameter Exploration**
- **Boltzmann Exploration**
- **SARSA (State-Action-Reward-State-Action)**

Each directory contains detailed implementations and results that shed light on the capabilities and challenges of applying RL algorithms to a well-understood test environment in the field.

## Future Directions
The repository is continuously updated with new projects and experiments as we explore more complex problems and sophisticated algorithms in reinforcement learning.

Feel free to dive into each project directory for comprehensive code, insights, and analyses. Whether you're new to reinforcement learning or looking to expand your understanding of specific algorithms and their applications, there's something here for everyone. Stay tuned for more updates and new projects!

### Contributing
We welcome contributions from the community! If you have suggestions, improvements, or want to contribute new experiments, please feel free to submit a pull request or open an issue.

Happy exploring and learning!
